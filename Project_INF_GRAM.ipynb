{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Project INF-GRAM.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rakelup/DESU-IA4PH-InfoGRAM/blob/main/Project_INF_GRAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DESU IA4 HEALH"
      ],
      "metadata": {
        "id": "vKt6clKdsiBe"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5Rk0g8UNmmA"
      },
      "source": [
        "# **Project INF-GRAM**\n",
        "\n",
        "\n",
        "The first project of INF-PROF was aimed at cleaning and exploring a dataset with pandas library. In this project you will have to build different models in order to classify the patients into two classes, _ckd_ or _notckd_. For this work you will have to use the sklearn library. The dataset is a cleaned version of the dataset of the INF-PROF project. You will have to do some description of the datasets, build some Machine Learning models and use the sklearn to tuned the parameters of these models and report the results with tables and graphics. \n",
        " \n",
        "The `classification` column is the one to predict with `ckd` if the patient was diagnosed with CKD and `notckd` if not. A full dictionary is presented below:\n",
        "\n",
        "\n",
        "**Dictionary:**\n",
        "\n",
        "* __id__: Identifiant of the patient __[Numerical]__\n",
        "* __age__: Age in years __[Numerical]__\n",
        "* __bp__: Blood Pressure in mm/Hg __[Numerical]__\n",
        "* __sg__: Urine specific gravity __[one of (1.005, 1.010, 1.015, 1.020, 1.025)]__\n",
        "* __al__: Albumin in urine. __[one of (0, 1, 2, 3, 4, 5)]__\n",
        "* __su__: Sugar in urine. __[one of (0, 1, 2, 3, 4, 5)]__\n",
        "* __rbc__: Red blood cells in urine. __[1 = \"normal\", 0 = \"abnormal\"]__\n",
        "* __pc__: Pus cell in urine. __[1 = \"normal\", 0 = \"abnormal\"]__\n",
        "* __pcc__: Pus cell clumps in urine. __[1 = \"present\", 0 = \"notpresent\"]__\n",
        "* __ba__: Bacteria in urine. __[1 = \"present\", 0 =\"notpresent\"]__\n",
        "* __bgr__: Blood glucose random in mgs/dl __[Numerical]__\n",
        "* __bu__: Blood urea in mgs/dl __[Numerical]__\n",
        "* __sc__: Serum creatinine in mgs/dl __[Numerical]__\n",
        "* __sod__: Sodium in mEq/L __[Numerical]__\n",
        "* __pot__: Potassium in mEq/L __[Numerical]__\n",
        "* __hemo__: Hemoglobin in gms __[Numerical]__\n",
        "* __pcv__: Packed cell volume (volume percentage) __[Numerical]__\n",
        "* __wc__: White blood cell count in cells/cumm __[Numercial]__\n",
        "* __rc__: Red blood cell count in millions/cmm __[Numerical]__\n",
        "* __htn__: Hypertension. __[1 = \"yes\", 0 = \"no\"]__\n",
        "* __dm__: Diabetes mellitus. __[1 = \"yes\", 0 = \"no\"]__\n",
        "* __cad__: Coronary artery disease. __[1 = \"yes\", 0 = \"no\"]__\n",
        "* __appet__: Appetite. __[1 = \"good\", 0 = \"poor\"]__\n",
        "* __pe__: Pedal edema. __[1 = \"yes\", 0 = \"no\"]__\n",
        "* __ane__: Anemia. __[1 = \"yes\", 0 = \"no\"]__\n",
        "* __classification__: Chronic kidneys disease. __[one of ('ckd', 'notckd')]__.\n",
        "\n",
        "The dataset is available here [https://raw.githubusercontent.com/NicolasNgo/Project1_INF_GRAM/main/ckd.csv](https://raw.githubusercontent.com/NicolasNgo/Project1_INF_GRAM/main/ckd.csv). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xu3jwu6cczOX"
      },
      "source": [
        "## **Task 1: Importation of the dataset**\n",
        "\n",
        "Import the dataset in a pandas' dataframe format. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84rwDWwNxu4H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hP5WMbB_d5RS"
      },
      "source": [
        "## **Task 2: Check the data**\n",
        "Give a first glance at the first rows of the dataset and answer these questions:  \n",
        "* How many patients are there ?\n",
        "* How many features were collected ?\n",
        "* Is there any missing values ? \n",
        "* What is the proportion of patients diagnosed with CKD ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2x0Ia55xv_9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ko0L5lWApTh0"
      },
      "source": [
        "## **Task 3: Preprocessing**\n",
        "A preprocessing step gave us the important features for the classification of CKD. The features are the age, the urine specific gravity (sg), the albumin in urine (al), the blood urea (bu), the serum creatinine (sc), the hemoglobin (hemo) and the packed cell volume (pcv). Create a new dataframe with only these features and the target feature, _classification_.  For the rest of the project we will be working with this dataset. \n",
        "\n",
        "Give some descriptive statistics of the new dataframe. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCFBlaHPxx69"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2HEde4dh-K9"
      },
      "source": [
        "## **Task 4: Visualization**\n",
        "\n",
        "For each feature, plot an histogram of the values in each class (_ckd_ and _notckd_) as well as the scatter plots of the varibales by pairs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD1aF9VOxy8l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDKaw-dOq43d"
      },
      "source": [
        "## **Task 5: Correlation matrix**\n",
        "\n",
        "Compute the correlation matrix of the features, give a graphic representing this correlation matrix and make some comments about the correlation in the dataset. \n",
        "\n",
        "The correlation matrix should include the correlation with the _classification_ feature. For this task you'll have to transform the values of _classification_ to binary values. I recommend that you use 1 for _ckd_ and 0 for _notckd_. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFw1rjSax1IH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmJdGsY3PG1M"
      },
      "source": [
        "## **Task 6: Splitting the data**\n",
        "\n",
        "Split the dataset into two dataset, one for the training and one for the validation of your models. Use 70% of the data for the training dataset and 30% of the data for the validation dataset. \n",
        "\n",
        "Give the number of patients and CKD in both dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdI1063Ax7iO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-47u6sPWYSs"
      },
      "source": [
        "## **Task 7: Models building and evaluation**\n",
        "We want to build the best model, in terms of F1-score, for this task you will have to test multiple machine learning models, tune the hyperparameters using gridsearch, test your models on the validation dataset, print the ROC curve and the confusion matrix for each model and report the results with a table.\n",
        "\n",
        "You'll have to test 3 models:\n",
        "* The Support Vector Machine\n",
        "* The random forest algorithm.\n",
        "* Adaboost classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpQxxQrWx_rN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfQBAYgSRfr1"
      },
      "source": [
        "### **SVM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIj6SpEIyDBW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tv3cTsYMtf3G"
      },
      "source": [
        "### **Random forest model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-l7l8diuyGQW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Ada boost classifier**"
      ],
      "metadata": {
        "id": "2b8H125dNcfp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "S9e5qAYLNhX2"
      }
    }
  ]
}